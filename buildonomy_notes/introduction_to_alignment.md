# Links to Start Exploring AI Alignment

https://www.science.org/content/article/computer-programs-can-learn-what-other-programs-are-thinking
:   Anyone who's had a frustrating interaction with Siri or Alexa knows that digital assistants just
    don't get humans. What they need is what psychologists call theory of mind, an awareness of
    others' beliefs and desires. Now, computer scientists have created an artificial intelligence
    (AI) that can probe the "minds" of other computers and predict their actions, the first step to
    fluid collaboration among machines—and between machines and people.

https://towardsdatascience.com/the-future-and-philosophy-of-machine-consciousness-872f272875c8
:   Today, we’ll explore questions related to machine consciousness, such as:
    - Can a machine think
    - Can a machine experience emotions
    - Can a machine be conscious
    We’ll try to keep things objective, taking diverse perspectives from multiple sources.

https://www.lesswrong.com/
:   We are a community dedicated to improving our reasoning and decision-making. We seek to hold
    true beliefs and to be effective at accomplishing our goals. More generally, we work to develop
    and practice the art of human rationality.[1]

https://plato.stanford.edu/entries/consciousness/
:   Perhaps no aspect of mind is more familiar or more puzzling than consciousness and our conscious
    experience of self and world. The problem of consciousness is arguably the central issue in
    current theorizing about the mind. Despite the lack of any agreed upon theory of consciousness,
    there is a widespread, if less than universal, consensus that an adequate account of mind
    requires a clear understanding of it and its place in nature. We need to understand both what
    consciousness is and how it relates to other, non-conscious, aspects of reality.

https://stampy.ai/wiki/Stampy
:   The Stampy project is an open effort to build a comprehensive FAQ about artificial intelligence
    existential safety—the field trying to make sure that when we build superintelligent artificial
    systems they are aligned with human values so that they do the kinds of things we would like
    them to do.

https://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0198739834/
:   Superintelligence asks the questions: What happens when machines surpass humans in general
    intelligence? Will artificial agents save or destroy us? Nick Bostrom lays the foundation for
    understanding the future of humanity and intelligent life.

https://ai.facebook.com/blog/self-supervised-learning-the-dark-matter-of-intelligence/
:   "A working hypothesis is that generalized knowledge about the world, or common sense, forms the
    bulk of biological intelligence in both humans and animals. This common sense ability is taken
    for granted in humans and animals, but has remained an open challenge in AI research since its
    inception. In a way, common sense is the dark matter of artificial intelligence."

    "Common sense helps people learn new skills without requiring massive amounts of teaching for
    every single task. For example, if we show just a few drawings of cows to small children,
    they’ll eventually be able to recognize any cow they see."

    I think the training approach outlined here makes sense, and also may implicitly introduce a
    property of 'subjectivity' into the model as it learns.

https://www.wired.com/story/artificial-intelligence-data-future-optimization-antifragility/
:   These blueprints aren’t Neurolinks, Artificial General Intelligence, or some other quixotic
    technology. They’re design innovations that we can implement, now.

    All they require is the courage to leave behind big data and its false promise of perfect
    intelligence. All they require is accepting that, in our uncertain and ever-changing world, it’s
    smarter to be creatively adequate than optimally accurate. Because it’s better to bounce back
    than break.

https://ought.org/updates/2022-04-06-process
:   We can think about machine learning systems on a spectrum from process-based to outcome-based:

    - Process-based systems are built on human-understandable task decompositions, with direct
      supervision of reasoning steps.
    - Outcome-based systems are built on end-to-end optimization, with supervision of final results.

https://www.alignmentforum.org/s/Rm6oQRJJmhGCcLvxh
:   This is a sequence by Scott Garrabrant and Abram Demski on one current way of thinking about
    alignment: Embedded Agency.
